# .github/workflows/ci.yml
# Continuous Integration Pipeline
name: CI Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  PYTHON_VERSION: '3.10'

jobs:
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort mypy
      
      - name: Run Black (code formatting)
        run: black --check src/ tests/
      
      - name: Run isort (import sorting)
        run: isort --check-only src/ tests/
      
      - name: Run Flake8 (linting)
        run: flake8 src/ tests/ --max-line-length=100 --ignore=E203,W503
      
      - name: Run MyPy (type checking)
        run: mypy src/ --ignore-missing-imports

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-mock
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --junitxml=test-results.xml \
            -v
      
      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
      
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results
          path: test-results.xml

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-mock
      
      - name: Run integration tests
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_NAME: test_db
          DB_USER: test_user
          DB_PASSWORD: test_pass
        run: |
          pytest tests/integration/ -v

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Run Bandit (security linting)
        run: |
          pip install bandit
          bandit -r src/ -f json -o bandit-report.json
      
      - name: Run Safety (dependency vulnerability check)
        run: |
          pip install safety
          safety check --json
      
      - name: Upload security reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-reports
          path: bandit-report.json

  build-docker:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Login to DockerHub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./deployment/docker/Dockerfile
          push: true
          tags: |
            kenyaenergyai/ml-service:latest
            kenyaenergyai/ml-service:${{ github.sha }}
          cache-from: type=registry,ref=kenyaenergyai/ml-service:buildcache
          cache-to: type=registry,ref=kenyaenergyai/ml-service:buildcache,mode=max

---

# .github/workflows/model_training.yml
# Automated Model Training and Deployment
name: Model Training Pipeline

on:
  schedule:
    - cron: '0 0 * * 0'  # Weekly on Sunday
  workflow_dispatch:  # Manual trigger

jobs:
  train-model:
    name: Train and Validate Model
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install mlflow
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Download training data
        run: |
          aws s3 cp s3://kenya-energy-data/training/latest/ ./data/training/ --recursive
      
      - name: Train credit scoring model
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
        run: |
          python scripts/train_model.py \
            --model-type credit_scoring \
            --data-path ./data/training/ \
            --output-dir ./models/
      
      - name: Evaluate model performance
        run: |
          python scripts/evaluate_model.py \
            --model-path ./models/credit_scoring_latest.json \
            --test-data ./data/training/test.parquet \
            --threshold 0.75
      
      - name: Check for bias
        run: |
          python scripts/bias_check.py \
            --model-path ./models/credit_scoring_latest.json \
            --test-data ./data/training/test.parquet
      
      - name: Upload model artifacts
        if: success()
        run: |
          aws s3 cp ./models/ s3://kenya-energy-data/models/$(date +%Y%m%d)/ --recursive
      
      - name: Notify on Slack
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Model training pipeline completed'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}

---

# .gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
venv/
env/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Jupyter
.ipynb_checkpoints
*.ipynb

# Data
data/raw/
data/processed/
*.csv
*.parquet
*.pkl
*.h5

# Models
models/saved/
*.json
*.pkl
*.h5

# Logs
logs/
*.log

# Environment variables
.env
.env.local

# Testing
.coverage
htmlcov/
.pytest_cache/
test-results.xml

# MLflow
mlruns/
mlartifacts/

# AWS
.aws/

# MacOS
.DS_Store

# Temporary files
tmp/
temp/
*.tmp

---

# Git Branch Strategy Documentation
# BRANCHING_STRATEGY.md

## Branch Structure

### Main Branches
- **main**: Production-ready code. Protected branch requiring PR reviews.
- **develop**: Integration branch for features. Automatically deployed to staging.

### Supporting Branches
- **feature/***: New features (e.g., feature/credit-scoring-v2)
- **bugfix/***: Bug fixes (e.g., bugfix/data-validation-error)
- **hotfix/***: Urgent production fixes (e.g., hotfix/payment-api-crash)
- **release/***: Release preparation (e.g., release/v1.2.0)

## Workflow

1. **Feature Development**
   ```bash
   git checkout develop
   git pull origin develop
   git checkout -b feature/new-feature
   # Make changes
   git add .
   git commit -m "feat: add new feature"
   git push origin feature/new-feature
   # Create PR to develop
   ```

2. **Model Updates**
   ```bash
   git checkout develop
   git checkout -b feature/model-improvement
   # Update model
   git add src/models/
   git commit -m "model: improve credit scoring accuracy by 5%"
   git push origin feature/model-improvement
   ```

3. **Hotfix**
   ```bash
   git checkout main
   git checkout -b hotfix/critical-bug
   # Fix bug
   git commit -m "fix: resolve payment processing error"
   git push origin hotfix/critical-bug
   # Create PR to main AND develop
   ```

## Commit Message Convention

Follow Conventional Commits:
- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation changes
- `style:` Code style changes
- `refactor:` Code refactoring
- `test:` Test additions/changes
- `chore:` Maintenance tasks
- `model:` ML model changes

## Version Tagging

```bash
git tag -a v1.2.0 -m "Release version 1.2.0"
git push origin v1.2.0
```
